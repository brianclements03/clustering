{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e991676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wrangle\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b918bebf",
   "metadata": {},
   "source": [
    "### 1. Acquire data from mySQL using the python module to connect and query. You will want to end with a single dataframe. Make sure to include: the logerror, all fields related to the properties that are available. You will end up using all the tables in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcdedbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquiring the data using the wrangle\n",
    "zillow_sql_query = wrangle.get_zillow_data()\n",
    "# I am working with a copy of the SQL query to be able to access it faster\n",
    "df = zillow_sql_query.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a4b3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow_sql_query.shape, df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c5fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6bc2b8",
   "metadata": {},
   "source": [
    "### Summarize your data (summary stats, info, dtypes, shape, distributions, value_counts, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83293a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1905cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b2eb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df.describe().T, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654ede06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27d1bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what percentage of null values for every column.  weird that all my buildingclasstypeid\n",
    "# are null after sql query, there were values before\n",
    "\n",
    "df.isnull().sum()/len(df)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d4eff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e09400b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df.hist()\n",
    "# plt.tight_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bd1833",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How many nulls have in each row?\n",
    "# ...as in... 11995 rows have 33 nulls?\n",
    "df.isnull().sum(axis =1).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9062f1",
   "metadata": {},
   "source": [
    "### 3. Write a function that takes in a dataframe of observations and attributes and returns a dataframe where each row is an atttribute name, the first column is the number of rows with missing values for that attribute, and the second column is percent of total rows that have missing values for that attribute. Run the function and document takeaways from this on how you want to handle missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a583f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_col_wise(df):\n",
    "    '''\n",
    "    Function that takes in a df and returns a list of attributes with the number and percent\n",
    "    of missing values for that attribute.\n",
    "    '''\n",
    "    new_df = pd.DataFrame(df.isnull().sum())\n",
    "    new_df['number_missing'] = df.isnull().sum()\n",
    "    new_df['percent_missing'] = df.isnull().sum()/len(df)*100\n",
    "    new_df.drop([0], axis=1, inplace=True)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d71b975",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_cols = missing_values_col_wise(df)\n",
    "missing_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bc4a06",
   "metadata": {},
   "source": [
    "### Takeaways, missing values: \n",
    "Drop all columns over 50% except...\n",
    "- pool count: i think pool count is 0 unless otherwise specified\n",
    "- fireplace count: same\n",
    "- unit count...see below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624c8d88",
   "metadata": {},
   "source": [
    "### 4. Write a function that takes in a dataframe and returns a dataframe with 3 columns: the number of columns missing, percent of columns missing, and number of rows with n columns missing. Run the function and document takeaways from this on how you want to handle missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b8fc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_row_wise(df):\n",
    "    '''\n",
    "    Function that takes in a df and returns a list of rows with the number and percent\n",
    "    of missing values.\n",
    "    '''\n",
    "    new_df = pd.DataFrame(df.isnull().sum(axis =1).value_counts())\n",
    "    new_df['percent_missing'] = new_df.index/len(df.columns)*100\n",
    "    new_df['num_of_rows'] = df.isnull().sum(axis =1).value_counts()\n",
    "    new_df.drop([0], axis=1, inplace=True)\n",
    "    new_df.index.rename('num_cols_missing_from_row', inplace = True)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb6fdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_rows = missing_values_row_wise(df)\n",
    "missing_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcafa01b",
   "metadata": {},
   "source": [
    "### Takeaways, missing values row-wise: let's drop everything above fifty percent...actually, first let's drop columns and repeat process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d42e86",
   "metadata": {},
   "source": [
    "## Prepare\n",
    "\n",
    "### 1. Remove any properties that are likely to be something other than single unit properties. (e.g. no duplexes, no land/lot, ...). There are multiple ways to estimate that a property is a single unit, and there is not a single \"right\" answer. But for this exercise, do not purely filter by unitcnt as we did previously. Add some new logic that will reduce the number of properties that are falsely removed. You might want to use # bedrooms, square feet, unit type or the like to then identify those with unitcnt not defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5459b7ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.unitcnt.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3d4e4a",
   "metadata": {},
   "source": [
    "Start by removing anything above 1.0 units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c3e333",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.bedroomcnt.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d4edf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.calculatedfinishedsquarefeet.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1e1b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at value counts for 'unitcnt'\n",
    "\n",
    "df.unitcnt.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642fc671",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (df.calculatedfinishedsquarefeet/df.bedroomcnt).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d982513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict df to only properties that meet single unit criteria\n",
    "\n",
    "single_use = [261, 262, 263, 264, 266, 268, 273, 276, 279]\n",
    "df = df[df.propertylandusetypeid.isin(single_use)]\n",
    "    \n",
    "    \n",
    "# Restrict df to only those properties with at least 1 bath & bed and >350 sqft area\n",
    "df = df[(df.bedroomcnt > 0) & (df.bathroomcnt > 0) & ((df.unitcnt<=1)|df.unitcnt.isnull()) & (df.calculatedfinishedsquarefeet>350)]\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b814dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df, prop_required_row, prop_required_col):\n",
    "    ''' function which takes in a dataframe, proportion of non-null rows and columns\n",
    "    (respectively) required to prevent the columns and rows being dropped:'''\n",
    "    \n",
    "    #drop columns with nulls\n",
    "    threshold = int(prop_required_col * len(df.index)) # Require that many non-NA values.\n",
    "    df.dropna(axis = 1, thresh = threshold, inplace = True)\n",
    "    \n",
    "    #drop rows with nulls\n",
    "    threshold = int(prop_required_row * len(df.columns)) # Require that many non-NA values.\n",
    "    df.dropna(axis = 0, thresh = threshold, inplace = True)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6624d3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = handle_missing_values(df, .7, .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60682ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0c36b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27962b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.heatingorsystemdesc.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddf53e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use your judgement to remove certain columns which you don't need\n",
    "\n",
    "cols_to_remove = ['id',\n",
    "       'calculatedbathnbr', 'finishedsquarefeet12', 'heatingorsystemtypeid'\n",
    "       ,'propertycountylandusecode', 'propertylandusetypeid','propertyzoningdesc'\n",
    "       ,'regionidcounty', \n",
    "        'censustractandblock', 'propertylandusedesc', 'unitcnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14bacd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_columns(df, cols_to_remove):  \n",
    "    df = df.drop(columns=cols_to_remove)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e534cb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_columns(df,cols_to_remove)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a760ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0569b9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.heatingorsystemdesc.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06027c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure i agree that there are so many homes lacking heat in southern CA\n",
    "# but i do agree the attribute should be dropped\n",
    "\n",
    "df.drop(columns = 'heatingorsystemdesc', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9655d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14986ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buildingqualitytypeid\n",
    "# Overall assessment of condition of the building from \n",
    "# low number = best quality\n",
    "# higher numbers = worse quality\n",
    "\n",
    "df.buildingqualitytypeid.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707d85a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_col_wise(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b9fa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the median value of buildingqualitytypeid?\n",
    "\n",
    "df.buildingqualitytypeid.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2c5f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should I fill missing values for buildingqualitytypeid with median value?\n",
    "df.buildingqualitytypeid.fillna(6.0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8abf5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fabd17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at lot-size distribution\n",
    "df.lotsizesquarefeet.hist(bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6208ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# median lot size?\n",
    "df.lotsizesquarefeet.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290742d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.lotsizesquarefeet.fillna(7313,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eadc51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5114b5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am going to drop the rest of nulls \n",
    "\n",
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e6b502",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1072d23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e312d34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa630a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at distributions for all columns\n",
    "\n",
    "df.hist(figsize=(24, 10), bins=20)\n",
    "plt.tight_layout;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79632339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove properties valued more than 5 million dollars\n",
    "\n",
    "df = df[df.taxvaluedollarcnt < 5_000_000]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88c29698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read and wrangle data:\n",
    "\n",
    "def wrangle_zillow():\n",
    "    df = pd.read_csv('zillow_df.csv')\n",
    "    \n",
    "    # Restrict df to only properties that meet single unit use criteria\n",
    "    single_use = [261, 262, 263, 264, 266, 268, 273, 276, 279]\n",
    "    df = df[df.propertylandusetypeid.isin(single_use)]\n",
    "    \n",
    "    # Restrict df to only those properties with at least 1 bath & bed and 350 sqft area\n",
    "    df = df[(df.bedroomcnt > 0) & (df.bathroomcnt > 0) & ((df.unitcnt<=1)|df.unitcnt.isnull())\\\n",
    "            & (df.calculatedfinishedsquarefeet>350)]\n",
    "\n",
    "    # Handle missing values i.e. drop columns and rows based on a threshold\n",
    "    df = handle_missing_values(df,.7,.5\n",
    "                              )\n",
    "    \n",
    "    # Add column for counties\n",
    "    df['county'] = np.where(df.fips == 6037, 'Los_Angeles',\n",
    "                           np.where(df.fips == 6059, 'Orange', \n",
    "                                   'Ventura'))    \n",
    "    # drop columns not needed\n",
    "    df = remove_columns(df, ['id',\n",
    "       'calculatedbathnbr', 'finishedsquarefeet12', 'heatingorsystemtypeid'\n",
    "       ,'propertycountylandusecode', 'propertylandusetypeid','propertyzoningdesc'\n",
    "       ,'regionidcounty', \n",
    "        'censustractandblock', 'propertylandusedesc', 'unitcnt'])\n",
    "\n",
    "\n",
    "#     replace nulls in unitcnt with 1\n",
    "#     df.unitcnt.fillna(1, inplace = True)\n",
    "    \n",
    "    # assume that since this is Southern CA, null means 'None' for heating system\n",
    "#     df.heatingorsystemdesc.fillna('None', inplace = True)\n",
    "\n",
    "    # actually, I'm not assuming this, and I am dropping the heatingsystem col\n",
    "    df.drop(columns = 'heatingorsystemdesc', inplace = True)\n",
    "    \n",
    "    # replace nulls with median values for select columns\n",
    "    df.lotsizesquarefeet.fillna(7313, inplace = True)\n",
    "    df.buildingqualitytypeid.fillna(6.0, inplace = True)\n",
    "\n",
    "    # Columns to look for outliers\n",
    "    df = df[df.taxvaluedollarcnt < 5_000_000]\n",
    "    df = df[df.calculatedfinishedsquarefeet < 8000]\n",
    "    \n",
    "    # Just to be sure we caught all nulls, drop them here\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51ccb96e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7fe64280e016>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrangle_zillow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-10d616878699>\u001b[0m in \u001b[0;36mwrangle_zillow\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwrangle_zillow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'zillow_df.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Restrict df to only properties that meet single unit use criteria\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = wrangle_zillow()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf75e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f9b1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.transactiondate.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d878ef63",
   "metadata": {},
   "source": [
    "# RETURN TO THIS NOTEBOOK TO COMPLETE THE MALL DATA EXERCISES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdc6dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
