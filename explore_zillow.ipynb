{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0804ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from env import host, user, password\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import env\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "import scipy\n",
    "import sklearn.linear_model\n",
    "import sklearn.preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import wrangle\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d9becb",
   "metadata": {},
   "source": [
    "### 1. Ask at least 5 questions about the data, keeping in mind that your target variable is logerror. e.g. Is logerror significantly different for properties in LA County vs Orange County vs Ventura County?\n",
    "\n",
    "### 2. Answer those questions through a mix of statistical tests and visualizations.\n",
    "\n",
    "### 3. Bonus: Compute the mean(logerror) by zipcode and the overall mean(logerror). Write a loop that will run a t-test between the overall mean and the mean for each zip code. We want to identify the zip codes where the error is significantly higher or lower than the expected error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bac7169",
   "metadata": {},
   "source": [
    "## Before I get further down any rabbit hole, let's scale and split this data please\n",
    "\n",
    "The wrange_zillow function is pretty good, just needs to be added to scale and split i think.\n",
    "\n",
    "# NOTES TO THE EFFECT:\n",
    "I have moved a number of operations from the wrangle function to the clean_and_prep function--i want the wrangle function to be a simple wrapper for all the other functions in the script\n",
    "    - I'm expecting errors as a result that will need troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fe13bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE WRANGLE FUNCTION PERFORMS THE FOLLOWIN, IN BROAD STROKES:\n",
    "# 1. Get the data via SQL query\n",
    "# 2. Clean and prep the data\n",
    "# 3. Encode the appropriate columns (only ['county'] for now)\n",
    "# 4. Split the data: train, validate, test and X_ vs y_ splits as well\n",
    "# 5. Scale the data (all train, validate and test, and all X_ and y_ splits are scaled)\n",
    "\n",
    "df, train, validate, test, X_train, y_train, X_validate, y_validate, X_test, y_test, \\\n",
    "train_scaled, X_train_scaled, y_train_scaled, validate_scaled, X_validate_scaled, \\\n",
    "y_validate_scaled, test_scaled, X_test_scaled, y_test_scaled \\\n",
    "= wrangle.wrangle_zillow()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1f96cd",
   "metadata": {},
   "source": [
    "# COMPLETE AND RUN YOUR CLEAN_AND_PREP FUNCTION BEFORE PROCEEDING FOR CLARITY\n",
    "#### adding it inside of 'wrangle', or as a separate step?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aafb8e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61427, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e0894a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parcelid                 int64\n",
       "bathrooms              float64\n",
       "bedrooms               float64\n",
       "condition              float64\n",
       "sq_ft                  float64\n",
       "full_baths             float64\n",
       "latitude               float64\n",
       "longitude              float64\n",
       "lot_size               float64\n",
       "census_tract           float64\n",
       "city_id                float64\n",
       "zip                    float64\n",
       "rooms                  float64\n",
       "structure_value        float64\n",
       "tax_value              float64\n",
       "year_assessed          float64\n",
       "land_value             float64\n",
       "tax_amount             float64\n",
       "logerror               float64\n",
       "age                    float64\n",
       "sq_ft_per_bathroom     float64\n",
       "sq_ft_per_bedroom      float64\n",
       "sq_ft_per_room         float64\n",
       "has_half_bath             bool\n",
       "age_bin               category\n",
       "Los_Angeles              uint8\n",
       "Orange                   uint8\n",
       "Ventura                  uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "147b8651",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10946379    2\n",
      "17280166    2\n",
      "12224279    2\n",
      "12099888    2\n",
      "11065727    2\n",
      "           ..\n",
      "12068177    1\n",
      "14305540    1\n",
      "14028116    1\n",
      "10860236    1\n",
      "12853244    1\n",
      "Name: parcelid, Length: 61280, dtype: int64\n",
      "2.0    28209\n",
      "3.0    12428\n",
      "1.0    12168\n",
      "2.5     6082\n",
      "1.5     1346\n",
      "4.0      828\n",
      "3.5      366\n",
      "Name: bathrooms, dtype: int64\n",
      "3.0    26241\n",
      "2.0    17415\n",
      "4.0    12462\n",
      "1.0     3213\n",
      "5.0     1905\n",
      "6.0      191\n",
      "Name: bedrooms, dtype: int64\n",
      "6.0     34688\n",
      "8.0     12146\n",
      "4.0      7951\n",
      "7.0      3747\n",
      "5.0      1458\n",
      "9.0       997\n",
      "11.0      241\n",
      "3.0       145\n",
      "10.0       30\n",
      "12.0       17\n",
      "1.0         4\n",
      "2.0         3\n",
      "Name: condition, dtype: int64\n",
      "1200.0    169\n",
      "1120.0    161\n",
      "1080.0    129\n",
      "1260.0    115\n",
      "1040.0    112\n",
      "         ... \n",
      "2964.0      1\n",
      "658.0       1\n",
      "3219.0      1\n",
      "3086.0      1\n",
      "3150.0      1\n",
      "Name: sq_ft, Length: 2745, dtype: int64\n",
      "2.0    34304\n",
      "1.0    13514\n",
      "3.0    12781\n",
      "4.0      828\n",
      "Name: full_baths, dtype: int64\n",
      "33665651.0    38\n",
      "33766300.0    34\n",
      "34056700.0    30\n",
      "34225100.0    29\n",
      "34410700.0    27\n",
      "              ..\n",
      "34037540.0     1\n",
      "34564093.0     1\n",
      "34349520.0     1\n",
      "33851667.0     1\n",
      "34143248.0     1\n",
      "Name: latitude, Length: 50080, dtype: int64\n",
      "-118438000.0    62\n",
      "-118435000.0    59\n",
      "-118377000.0    54\n",
      "-118188000.0    53\n",
      "-118390000.0    53\n",
      "                ..\n",
      "-117783222.0     1\n",
      "-118952921.0     1\n",
      "-119281072.0     1\n",
      "-117921153.0     1\n",
      "-117773963.0     1\n",
      "Name: longitude, Length: 48359, dtype: int64\n",
      "7313.0     7474\n",
      "6000.0      819\n",
      "5000.0      375\n",
      "7200.0      284\n",
      "7000.0      259\n",
      "           ... \n",
      "10744.0       1\n",
      "9155.0        1\n",
      "8015.0        1\n",
      "13486.0       1\n",
      "16446.0       1\n",
      "Name: lot_size, Length: 15245, dtype: int64\n",
      "6.059063e+07    60\n",
      "6.037137e+07    60\n",
      "6.037277e+07    51\n",
      "6.037139e+07    40\n",
      "6.059063e+07    39\n",
      "                ..\n",
      "6.037701e+07     1\n",
      "6.111008e+07     1\n",
      "6.059099e+07     1\n",
      "6.037107e+07     1\n",
      "6.037540e+07     1\n",
      "Name: census_tract, Length: 32386, dtype: int64\n",
      "12447.0    13539\n",
      "46298.0     2152\n",
      "5534.0      1772\n",
      "40227.0     1479\n",
      "54311.0     1420\n",
      "           ...  \n",
      "6822.0         3\n",
      "31134.0        3\n",
      "10815.0        3\n",
      "14906.0        2\n",
      "21395.0        1\n",
      "Name: city_id, Length: 174, dtype: int64\n",
      "97319.0    731\n",
      "97318.0    682\n",
      "96987.0    632\n",
      "96974.0    568\n",
      "97328.0    563\n",
      "          ... \n",
      "96956.0      4\n",
      "96329.0      2\n",
      "96039.0      2\n",
      "97092.0      1\n",
      "97111.0      1\n",
      "Name: zip, Length: 384, dtype: int64\n",
      "1.0     46034\n",
      "6.0      4194\n",
      "7.0      3528\n",
      "5.0      2754\n",
      "8.0      2521\n",
      "4.0      1214\n",
      "9.0       856\n",
      "3.0       183\n",
      "10.0      123\n",
      "11.0       11\n",
      "2.0         8\n",
      "12.0        1\n",
      "Name: rooms, dtype: int64\n",
      "100000.0    62\n",
      "90000.0     51\n",
      "95000.0     45\n",
      "200000.0    39\n",
      "150000.0    38\n",
      "            ..\n",
      "126193.0     1\n",
      "73191.0      1\n",
      "217475.0     1\n",
      "161321.0     1\n",
      "154255.0     1\n",
      "Name: structure_value, Length: 40318, dtype: int64\n",
      "450000.0    43\n",
      "350000.0    42\n",
      "375000.0    40\n",
      "500000.0    39\n",
      "400000.0    39\n",
      "            ..\n",
      "210982.0     1\n",
      "121291.0     1\n",
      "289552.0     1\n",
      "516060.0     1\n",
      "409961.0     1\n",
      "Name: tax_value, Length: 40129, dtype: int64\n",
      "2016.0    61427\n",
      "Name: year_assessed, dtype: int64\n",
      "21299.0     94\n",
      "22755.0     63\n",
      "30210.0     62\n",
      "16522.0     54\n",
      "16749.0     52\n",
      "            ..\n",
      "558517.0     1\n",
      "59600.0      1\n",
      "127170.0     1\n",
      "172086.0     1\n",
      "365784.0     1\n",
      "Name: land_value, Length: 41456, dtype: int64\n",
      "2418.22    8\n",
      "3720.52    7\n",
      "1725.20    5\n",
      "4401.72    5\n",
      "5022.42    4\n",
      "          ..\n",
      "4501.04    1\n",
      "2222.68    1\n",
      "2323.29    1\n",
      "5573.70    1\n",
      "4569.93    1\n",
      "Name: tax_amount, Length: 58372, dtype: int64\n",
      "0.000231    7\n",
      "0.002652    6\n",
      "0.000420    5\n",
      "0.008257    5\n",
      "0.003152    5\n",
      "           ..\n",
      "0.020736    1\n",
      "0.046424    1\n",
      "0.010790    1\n",
      "0.028261    1\n",
      "0.025578    1\n",
      "Name: logerror, Length: 60994, dtype: int64\n",
      "66.0     1797\n",
      "71.0     1492\n",
      "32.0     1446\n",
      "67.0     1423\n",
      "57.0     1415\n",
      "68.0     1376\n",
      "48.0     1364\n",
      "65.0     1266\n",
      "34.0     1190\n",
      "42.0     1190\n",
      "41.0     1179\n",
      "58.0     1164\n",
      "56.0     1124\n",
      "31.0     1112\n",
      "44.0     1098\n",
      "49.0     1096\n",
      "69.0     1089\n",
      "35.0     1069\n",
      "47.0     1058\n",
      "70.0     1056\n",
      "50.0     1021\n",
      "59.0     1004\n",
      "40.0     1003\n",
      "62.0     1001\n",
      "36.0      976\n",
      "37.0      966\n",
      "43.0      955\n",
      "64.0      929\n",
      "45.0      907\n",
      "74.0      888\n",
      "72.0      882\n",
      "33.0      845\n",
      "61.0      834\n",
      "73.0      824\n",
      "52.0      810\n",
      "60.0      801\n",
      "38.0      754\n",
      "63.0      741\n",
      "51.0      686\n",
      "46.0      673\n",
      "53.0      646\n",
      "39.0      610\n",
      "55.0      600\n",
      "15.0      570\n",
      "16.0      568\n",
      "14.0      542\n",
      "17.0      496\n",
      "18.0      489\n",
      "98.0      470\n",
      "20.0      465\n",
      "54.0      446\n",
      "80.0      443\n",
      "27.0      437\n",
      "30.0      434\n",
      "81.0      433\n",
      "97.0      427\n",
      "22.0      423\n",
      "29.0      421\n",
      "26.0      413\n",
      "19.0      401\n",
      "21.0      398\n",
      "96.0      392\n",
      "25.0      382\n",
      "24.0      382\n",
      "82.0      364\n",
      "23.0      360\n",
      "28.0      359\n",
      "95.0      342\n",
      "99.0      341\n",
      "75.0      330\n",
      "79.0      305\n",
      "83.0      297\n",
      "77.0      296\n",
      "13.0      275\n",
      "94.0      272\n",
      "93.0      264\n",
      "12.0      252\n",
      "84.0      214\n",
      "92.0      208\n",
      "11.0      200\n",
      "100.0     176\n",
      "85.0      176\n",
      "8.0       161\n",
      "101.0     157\n",
      "76.0      151\n",
      "91.0      149\n",
      "78.0      141\n",
      "7.0       133\n",
      "9.0       132\n",
      "109.0     124\n",
      "10.0      111\n",
      "111.0     109\n",
      "86.0       93\n",
      "108.0      90\n",
      "90.0       90\n",
      "110.0      89\n",
      "106.0      72\n",
      "107.0      67\n",
      "89.0       64\n",
      "112.0      61\n",
      "102.0      61\n",
      "116.0      56\n",
      "113.0      54\n",
      "103.0      49\n",
      "115.0      47\n",
      "87.0       44\n",
      "88.0       43\n",
      "104.0      39\n",
      "114.0      38\n",
      "105.0      33\n",
      "6.0        32\n",
      "118.0      17\n",
      "117.0      16\n",
      "120.0      15\n",
      "126.0      12\n",
      "119.0       9\n",
      "121.0       8\n",
      "131.0       7\n",
      "125.0       5\n",
      "136.0       5\n",
      "123.0       4\n",
      "133.0       3\n",
      "128.0       3\n",
      "134.0       2\n",
      "122.0       2\n",
      "139.0       1\n",
      "124.0       1\n",
      "141.0       1\n",
      "143.0       1\n",
      "5.0         1\n",
      "127.0       1\n",
      "Name: age, dtype: int64\n",
      "720.000000     162\n",
      "560.000000     147\n",
      "700.000000     145\n",
      "600.000000     144\n",
      "780.000000     143\n",
      "              ... \n",
      "884.800000       1\n",
      "1329.500000      1\n",
      "1006.400000      1\n",
      "1010.333333      1\n",
      "867.142857       1\n",
      "Name: sq_ft_per_bathroom, Length: 5709, dtype: int64\n",
      "432.000000    170\n",
      "480.000000    162\n",
      "420.000000    148\n",
      "520.000000    141\n",
      "400.000000    141\n",
      "             ... \n",
      "679.750000      1\n",
      "288.500000      1\n",
      "498.166667      1\n",
      "347.600000      1\n",
      "833.666667      1\n",
      "Name: sq_ft_per_bedroom, Length: 5229, dtype: int64\n",
      "1200.000000    129\n",
      "1120.000000    118\n",
      "1080.000000    109\n",
      "1570.000000     98\n",
      "1260.000000     94\n",
      "              ... \n",
      "411.833333       1\n",
      "223.285714       1\n",
      "277.428571       1\n",
      "354.375000       1\n",
      "2969.000000      1\n",
      "Name: sq_ft_per_room, Length: 7036, dtype: int64\n",
      "False    53620\n",
      "True      7807\n",
      "Name: has_half_bath, dtype: int64\n",
      "(40, 60]      19237\n",
      "(60, 80]      17264\n",
      "(20, 40]      13980\n",
      "(80, 100]      4859\n",
      "(0, 20]        4828\n",
      "(100, 120]     1203\n",
      "(120, 200]       56\n",
      "Name: age_bin, dtype: int64\n",
      "1    39146\n",
      "0    22281\n",
      "Name: Los_Angeles, dtype: int64\n",
      "0    44248\n",
      "1    17179\n",
      "Name: Orange, dtype: int64\n",
      "0    56325\n",
      "1     5102\n",
      "Name: Ventura, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebaa547",
   "metadata": {},
   "source": [
    "There may be a few duplicated parcel ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdbe688",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.full_baths.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ff1e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.has_half_bath.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafa7009",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.bathrooms - df.full_baths).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b7fda7",
   "metadata": {},
   "source": [
    "There aree 13 homes with 2 half baths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cb8444",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.bathrooms - df.full_baths) == 1.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308aa518",
   "metadata": {},
   "source": [
    "## Is there a time period that has a higher or lower log error?\n",
    "Bin the age group--ten bins? And see results.  Hue on county...if that makes a difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7852dd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='age', y='logerror', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9e69b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=df,\n",
    "    y='logerror',\n",
    "    x='age',\n",
    "    col=pd.cut(df.age, bins=[0, 20, 40, 60,80,100,120,200]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8874af5a",
   "metadata": {},
   "source": [
    "Things look a little tighter on either end...the 40-60 and the 60-80 look like they have a wider distribution of logerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f61d474",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.boxplot(x='age_bin', y='logerror', data= df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe76482",
   "metadata": {},
   "source": [
    "Still looks like there are more outliers in the middle, but this could be due to more data being available in those age bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994487fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df, x= df[df.age_bin == pd.Interval(0, 20)].logerror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94a7d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,7,1)\n",
    "sns.histplot(data=df, x= df[df.age_bin == pd.Interval(0, 20)].logerror)\n",
    "plt.title(\"0 to 20\")\n",
    "plt.subplot(1,7,2)\n",
    "sns.histplot(data=df, x= df[df.age_bin == pd.Interval(20, 40)].logerror)\n",
    "plt.title(\"20 to 40\")\n",
    "plt.subplot(1,7,3)\n",
    "sns.histplot(data=df, x= df[df.age_bin == pd.Interval(40, 60)].logerror)\n",
    "plt.title(\"40 to 60\")\n",
    "plt.subplot(1,7,4)\n",
    "sns.histplot(data=df, x= df[df.age_bin == pd.Interval(60, 80)].logerror)\n",
    "plt.title(\"60 to 80\")\n",
    "plt.subplot(1,7,5)\n",
    "sns.histplot(data=df, x= df[df.age_bin == pd.Interval(80, 100)].logerror)\n",
    "plt.title(\"80 to 100\")\n",
    "plt.subplot(1,7,6)\n",
    "sns.histplot(data=df, x= df[df.age_bin == pd.Interval(100, 120)].logerror)\n",
    "plt.title(\"100 to 120\")\n",
    "plt.subplot(1,7,7)\n",
    "sns.histplot(data=df, x= df[df.age_bin == pd.Interval(120, 200)].logerror)\n",
    "plt.title(\"120 and Up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d3db00",
   "metadata": {},
   "source": [
    "Looking at logerror by age_bin, they are generally normally distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b47d13",
   "metadata": {},
   "source": [
    "Maybe run an ANOVA test to see about the variances? \n",
    "\n",
    "First, Levene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa39525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#H0: Variances are equal\n",
    "#Ha: Variances are not equal\n",
    "\n",
    "stats.levene(\n",
    "    df[df.age_bin == pd.Interval(0, 20)].logerror,\n",
    "    df[df.age_bin == pd.Interval(20,40)].logerror,\n",
    "    df[df.age_bin == pd.Interval(40,60)].logerror,\n",
    "    df[df.age_bin == pd.Interval(60,80)].logerror,\n",
    "    df[df.age_bin == pd.Interval(80,100)].logerror,\n",
    "    df[df.age_bin == pd.Interval(100,120)].logerror,\n",
    "    df[df.age_bin == pd.Interval(120,200)].logerror\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ffe1c5",
   "metadata": {},
   "source": [
    "The results show that the null hypothesis is rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4236f3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.age_bin == pd.Interval(0, 20)].logerror.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa061669",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.age_bin == pd.Interval(120,200)].logerror.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1849b10",
   "metadata": {},
   "source": [
    "#### Anova testing of the logerror by age_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf98542",
   "metadata": {},
   "source": [
    "Set Hypothesis\n",
    "- 𝐻0 : Population means of logerror (by age_bin) are equal\n",
    "- 𝐻𝑎 : Population means of logerror (by age_bin) are not all equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07ebb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell runs an ANOVA test on the different 'age_bins'\n",
    "# We are demonstrating statistically that the age correlates to the logerror\n",
    "f, p = stats.f_oneway(\n",
    "    df[df.age_bin == pd.Interval(0, 20)].logerror,\n",
    "    df[df.age_bin == pd.Interval(20,40)].logerror,\n",
    "    df[df.age_bin == pd.Interval(40,60)].logerror,\n",
    "    df[df.age_bin == pd.Interval(60,80)].logerror,\n",
    "    df[df.age_bin == pd.Interval(80,100)].logerror,\n",
    "    df[df.age_bin == pd.Interval(100,120)].logerror,\n",
    "    df[df.age_bin == pd.Interval(120,200)].logerror\n",
    ")\n",
    "f, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0b8480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting our alpha and returning a statemtent on the validity of the ANOVA test by comparing alpha to the resulting p-value\n",
    "\n",
    "alpha = 0.05\n",
    "if p < alpha:\n",
    "    print(\"We reject H_O\")\n",
    "else:\n",
    "    print(\"We fail to reject $H_{0}$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19cb9c8",
   "metadata": {},
   "source": [
    "#### The anova test shows I can proceed with the understanding that the average logerror is different depending on the age of the home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3c0b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=df, y='logerror', x='age', col='county')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9fa1ab",
   "metadata": {},
   "source": [
    "This relplot shows age and logerror by count; any dignificant differences between the counties aren't clear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e53208",
   "metadata": {},
   "source": [
    "### What about a relationship between tax_value and logerror? (also: are these related targets?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f67c66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=df.tax_value, y=df.logerror, data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ec626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=df.tax_value, y=df.logerror, data=df, hue='county', alpha=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7305388f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=df.tax_value, y=df.logerror, data=df, col='county', alpha=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6488d71f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df.county=='Los_Angeles'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90246b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.county=='Orange'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e117118",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.county=='Ventura'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4675d7",
   "metadata": {},
   "source": [
    "### No clear impressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5db235",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='tax_value', y='logerror', data=df, scatter_kws={'alpha':.2},hue='county')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41db55ad",
   "metadata": {},
   "source": [
    "### Look like perfectly flat trend lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9ae7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
