{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0804ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from env import host, user, password\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import seaborn as sns\n",
    "import env\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "import scipy\n",
    "import sklearn.linear_model\n",
    "import sklearn.preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import wrangle\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d9becb",
   "metadata": {},
   "source": [
    "### 1. Ask at least 5 questions about the data, keeping in mind that your target variable is logerror. e.g. Is logerror significantly different for properties in LA County vs Orange County vs Ventura County?\n",
    "\n",
    "### 2. Answer those questions through a mix of statistical tests and visualizations.\n",
    "\n",
    "### 3. Bonus: Compute the mean(logerror) by zipcode and the overall mean(logerror). Write a loop that will run a t-test between the overall mean and the mean for each zip code. We want to identify the zip codes where the error is significantly higher or lower than the expected error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bac7169",
   "metadata": {},
   "source": [
    "## Before I get further down any rabbit hole, let's scale and split this data please\n",
    "\n",
    "The wrange_zillow function is pretty good, just needs to be added to scale and split i think.\n",
    "\n",
    "# NOTES TO THE EFFECT:\n",
    "I have moved a number of operations from the wrangle function to the clean_and_prep function--i want the wrangle function to be a simple wrapper for all the other functions in the script\n",
    "    - I'm expecting errors as a result that will need troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fe13bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df, train, validate, test, X_train, y_train, X_validate, y_validate, X_test, y_test, \\\n",
    "# train_scaled, X_train_scaled, y_train_scaled, validate_scaled, X_validate_scaled, \\\n",
    "# y_validate_scaled, test_scaled, X_test_scaled, y_test_scaled \\\n",
    "# = wrangle.wrangle_zillow()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8641357e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77574, 68)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GET\n",
    "df = wrangle.get_zillow_data()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d30c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN\n",
    "df = wrangle.clean_and_prep_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65890761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61427, 26)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9996cf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODE\n",
    "df = wrangle.encode_zillow(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9095b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61427, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "933588cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SPLIT\n",
    "train, validate, test, X_train, y_train, X_validate, y_validate, X_test, y_test = \\\n",
    "wrangle.split_zillow(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77fdcf2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34398, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "498c1911",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[2. 2. 2. ... 2. 3. 2.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6ba8cd0652df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bathrooms'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_scaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0mfirst_pass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'n_samples_seen_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         X = self._validate_data(X, reset=first_pass,\n\u001b[0m\u001b[1;32m    397\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m                                 force_all_finite=\"allow-nan\")\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'no_validation'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;31m# If input is 1D raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    638\u001b[0m                     \u001b[0;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[2. 2. 2. ... 2. 3. 2.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "train_scaled = scaler.fit_transform(train['bathrooms'])\n",
    "train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1f96cd",
   "metadata": {},
   "source": [
    "# COMPLETE AND RUN YOUR CLEAN_AND_PREP FUNCTION BEFORE PROCEEDING FOR CLARITY\n",
    "#### adding it inside of 'wrangle', or as a separate step?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0894a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147b8651",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdbe688",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.full_baths.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ff1e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.has_half_bath.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafa7009",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.bathrooms - df.full_baths).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b7fda7",
   "metadata": {},
   "source": [
    "There aree 13 homes with 2 half baths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cb8444",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.bathrooms - df.full_baths) == 1.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308aa518",
   "metadata": {},
   "source": [
    "## Is there a time period that has a higher or lower log error?\n",
    "Bin the age group--ten bins? And see results.  Hue on county...if that makes a difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7852dd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='age', y='logerror', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9e69b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=df,\n",
    "    y='logerror',\n",
    "    x='age',\n",
    "    col=pd.cut(df.age, bins=[0, 20, 40, 60,80,100,120,200]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8874af5a",
   "metadata": {},
   "source": [
    "Things look a little tighter on either end...the 40-60 and the 60-80 look like they have a wider distribution of logerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f61d474",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.boxplot(x='age_bin', y='logerror', data= df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe76482",
   "metadata": {},
   "source": [
    "Still looks like there are more outliers in the middle, but this could be due to more data being available in those age bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994487fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df, x= df[df.age_bin == pd.Interval(0, 20)].logerror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94a7d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,7,1)\n",
    "sns.histplot(data=df, x= df[df.age_bin == pd.Interval(0, 20)].logerror)\n",
    "plt.title(\"0 to 20\")\n",
    "plt.subplot(1,7,2)\n",
    "sns.histplot(data=df, x= df[df.age_bin == pd.Interval(20, 40)].logerror)\n",
    "plt.title(\"20 to 40\")\n",
    "plt.subplot(1,7,3)\n",
    "sns.histplot(data=df, x= df[df.age_bin == pd.Interval(40, 60)].logerror)\n",
    "plt.title(\"40 to 60\")\n",
    "plt.subplot(1,7,4)\n",
    "sns.histplot(data=df, x= df[df.age_bin == pd.Interval(60, 80)].logerror)\n",
    "plt.title(\"60 to 80\")\n",
    "plt.subplot(1,7,5)\n",
    "sns.histplot(data=df, x= df[df.age_bin == pd.Interval(80, 100)].logerror)\n",
    "plt.title(\"80 to 100\")\n",
    "plt.subplot(1,7,6)\n",
    "sns.histplot(data=df, x= df[df.age_bin == pd.Interval(100, 120)].logerror)\n",
    "plt.title(\"100 to 120\")\n",
    "plt.subplot(1,7,7)\n",
    "sns.histplot(data=df, x= df[df.age_bin == pd.Interval(120, 200)].logerror)\n",
    "plt.title(\"120 and Up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d3db00",
   "metadata": {},
   "source": [
    "Looking at logerror by age_bin, they are generally normally distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b47d13",
   "metadata": {},
   "source": [
    "Maybe run an ANOVA test to see about the variances? \n",
    "\n",
    "First, Levene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa39525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#H0: Variances are equal\n",
    "#Ha: Variances are not equal\n",
    "\n",
    "stats.levene(\n",
    "    df[df.age_bin == pd.Interval(0, 20)].logerror,\n",
    "    df[df.age_bin == pd.Interval(20,40)].logerror,\n",
    "    df[df.age_bin == pd.Interval(40,60)].logerror,\n",
    "    df[df.age_bin == pd.Interval(60,80)].logerror,\n",
    "    df[df.age_bin == pd.Interval(80,100)].logerror,\n",
    "    df[df.age_bin == pd.Interval(100,120)].logerror,\n",
    "    df[df.age_bin == pd.Interval(120,200)].logerror\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ffe1c5",
   "metadata": {},
   "source": [
    "The results show that the null hypothesis is rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4236f3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.age_bin == pd.Interval(0, 20)].logerror.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa061669",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.age_bin == pd.Interval(120,200)].logerror.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1849b10",
   "metadata": {},
   "source": [
    "#### Anova testing of the logerror by age_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf98542",
   "metadata": {},
   "source": [
    "Set Hypothesis\n",
    "- ùêª0 : Population means of logerror (by age_bin) are equal\n",
    "- ùêªùëé : Population means of logerror (by age_bin) are not all equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07ebb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell runs an ANOVA test on the different 'age_bins'\n",
    "# We are demonstrating statistically that the age correlates to the logerror\n",
    "f, p = stats.f_oneway(\n",
    "    df[df.age_bin == pd.Interval(0, 20)].logerror,\n",
    "    df[df.age_bin == pd.Interval(20,40)].logerror,\n",
    "    df[df.age_bin == pd.Interval(40,60)].logerror,\n",
    "    df[df.age_bin == pd.Interval(60,80)].logerror,\n",
    "    df[df.age_bin == pd.Interval(80,100)].logerror,\n",
    "    df[df.age_bin == pd.Interval(100,120)].logerror,\n",
    "    df[df.age_bin == pd.Interval(120,200)].logerror\n",
    ")\n",
    "f, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0b8480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting our alpha and returning a statemtent on the validity of the ANOVA test by comparing alpha to the resulting p-value\n",
    "\n",
    "alpha = 0.05\n",
    "if p < alpha:\n",
    "    print(\"We reject H_O\")\n",
    "else:\n",
    "    print(\"We fail to reject $H_{0}$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19cb9c8",
   "metadata": {},
   "source": [
    "#### The anova test shows I can proceed with the understanding that the average logerror is different depending on the age of the home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3c0b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=df, y='logerror', x='age', col='county')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9fa1ab",
   "metadata": {},
   "source": [
    "This relplot shows age and logerror by count; any dignificant differences between the counties aren't clear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e53208",
   "metadata": {},
   "source": [
    "### What about a relationship between tax_value and logerror? (also: are these related targets?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f67c66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=df.tax_value, y=df.logerror, data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ec626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=df.tax_value, y=df.logerror, data=df, hue='county', alpha=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7305388f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=df.tax_value, y=df.logerror, data=df, col='county', alpha=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6488d71f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df.county=='Los_Angeles'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90246b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.county=='Orange'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e117118",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.county=='Ventura'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4675d7",
   "metadata": {},
   "source": [
    "### No clear impressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5db235",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='tax_value', y='logerror', data=df, scatter_kws={'alpha':.2},hue='county')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41db55ad",
   "metadata": {},
   "source": [
    "### Look like perfectly flat trend lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9ae7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
