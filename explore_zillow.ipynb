{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0804ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from env import host, user, password\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import env\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "import scipy\n",
    "import sklearn.linear_model\n",
    "import sklearn.preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import wrangle\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d9becb",
   "metadata": {},
   "source": [
    "### 1. Ask at least 5 questions about the data, keeping in mind that your target variable is logerror. e.g. Is logerror significantly different for properties in LA County vs Orange County vs Ventura County?\n",
    "\n",
    "### 2. Answer those questions through a mix of statistical tests and visualizations.\n",
    "\n",
    "### 3. Bonus: Compute the mean(logerror) by zipcode and the overall mean(logerror). Write a loop that will run a t-test between the overall mean and the mean for each zip code. We want to identify the zip codes where the error is significantly higher or lower than the expected error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bac7169",
   "metadata": {},
   "source": [
    "## Before I get further down any rabbit hole, let's scale and split this data please\n",
    "\n",
    "The wrange_zillow function is pretty good, just needs to be added to scale and split i think.\n",
    "\n",
    "# NOTES TO THE EFFECT:\n",
    "I have moved a number of operations from the wrangle function to the clean_and_prep function--i want the wrangle function to be a simple wrapper for all the other functions in the script\n",
    "    - I'm expecting errors as a result that will need troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fe13bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df, train, validate, test, X_train, y_train, X_validate, y_validate, X_test, y_test, \\\n",
    "# train_scaled, X_train_scaled, y_train_scaled, validate_scaled, X_validate_scaled, \\\n",
    "# y_validate_scaled, test_scaled, X_test_scaled, y_test_scaled \\\n",
    "# = wrangle.wrangle_zillow()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8641357e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77574, 68)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GET\n",
    "df = wrangle.get_zillow_data()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d30c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN\n",
    "df = wrangle.clean_and_prep_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33e52bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61427, 26)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "861b5ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     46034\n",
       "6.0      4194\n",
       "7.0      3528\n",
       "5.0      2754\n",
       "8.0      2521\n",
       "4.0      1214\n",
       "9.0       856\n",
       "3.0       183\n",
       "10.0      123\n",
       "11.0       11\n",
       "2.0         8\n",
       "12.0        1\n",
       "Name: rooms, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rooms.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59077785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODE\n",
    "df = wrangle.encode_zillow(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c2b5b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61427, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "933588cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SPLIT\n",
    "train, validate, test, X_train, y_train, X_validate, y_validate, X_test, y_test = \\\n",
    "wrangle.split_zillow(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09b6b155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33333333, 0.8       , 0.81480195, ..., 0.36974359, 0.13299983,\n",
       "        0.08173686],\n",
       "       [0.33333333, 0.4       , 0.3123697 , ..., 0.1225641 , 0.09113909,\n",
       "        0.37333756],\n",
       "       [0.33333333, 0.2       , 0.2352328 , ..., 0.08461538, 0.12523719,\n",
       "        0.3030399 ],\n",
       "       ...,\n",
       "       [0.33333333, 0.2       , 0.21264767, ..., 0.07350427, 0.1140245 ,\n",
       "        0.05161495],\n",
       "       [0.66666667, 0.4       , 0.40514246, ..., 0.08125356, 0.12184463,\n",
       "        0.05520372],\n",
       "       [0.33333333, 0.4       , 0.3276581 , ..., 0.13008547, 0.09619918,\n",
       "        0.38727042]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train[['bathrooms','bedrooms','sq_ft','full_baths','lot_size','rooms'\\\n",
    "                 ,'structure_value','tax_value','land_value','tax_amount','logerror'\\\n",
    "                 ,'age','sq_ft_per_bathroom','sq_ft_per_bedroom','sq_ft_per_room']])\n",
    "train_scaled = scaler.transform(train[['bathrooms','bedrooms','sq_ft','full_baths','lot_size','rooms'\\\n",
    "                 ,'structure_value','tax_value','land_value','tax_amount','logerror'\\\n",
    "                 ,'age','sq_ft_per_bathroom','sq_ft_per_bedroom','sq_ft_per_room']])\n",
    "train_scaled = pd.DataFrame(data=train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1f96cd",
   "metadata": {},
   "source": [
    "# COMPLETE AND RUN YOUR CLEAN_AND_PREP FUNCTION BEFORE PROCEEDING FOR CLARITY\n",
    "#### adding it inside of 'wrangle', or as a separate step?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0894a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147b8651",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdbe688",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.full_baths.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ff1e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.has_half_bath.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafa7009",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.bathrooms - df.full_baths).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b7fda7",
   "metadata": {},
   "source": [
    "There aree 13 homes with 2 half baths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cb8444",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.bathrooms - df.full_baths) == 1.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308aa518",
   "metadata": {},
   "source": [
    "## Is there a time period that has a higher or lower log error?\n",
    "Bin the age group--ten bins? And see results.  Hue on county...if that makes a difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7852dd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='age', y='logerror', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9e69b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=df,\n",
    "    y='logerror',\n",
    "    x='age',\n",
    "    col=pd.cut(df.age, bins=[0, 20, 40, 60,80,100,120,200]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8874af5a",
   "metadata": {},
   "source": [
    "Things look a little tighter on either end...the 40-60 and the 60-80 look like they have a wider distribution of logerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f61d474",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.boxplot(x='age_bin', y='logerror', data= df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe76482",
   "metadata": {},
   "source": [
    "Still looks like there are more outliers in the middle, but this could be due to more data being available in those age bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994487fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df, x= df[df.age_bin == pd.Interval(0, 20)].logerror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94a7d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,7,1)\n",
    "sns.histplot(data=df, x= df[df.age_bin == pd.Interval(0, 20)].logerror)\n",
    "plt.title(\"0 to 20\")\n",
    "plt.subplot(1,7,2)\n",
    "sns.histplot(data=df, x= df[df.age_bin == pd.Interval(20, 40)].logerror)\n",
    "plt.title(\"20 to 40\")\n",
    "plt.subplot(1,7,3)\n",
    "sns.histplot(data=df, x= df[df.age_bin == pd.Interval(40, 60)].logerror)\n",
    "plt.title(\"40 to 60\")\n",
    "plt.subplot(1,7,4)\n",
    "sns.histplot(data=df, x= df[df.age_bin == pd.Interval(60, 80)].logerror)\n",
    "plt.title(\"60 to 80\")\n",
    "plt.subplot(1,7,5)\n",
    "sns.histplot(data=df, x= df[df.age_bin == pd.Interval(80, 100)].logerror)\n",
    "plt.title(\"80 to 100\")\n",
    "plt.subplot(1,7,6)\n",
    "sns.histplot(data=df, x= df[df.age_bin == pd.Interval(100, 120)].logerror)\n",
    "plt.title(\"100 to 120\")\n",
    "plt.subplot(1,7,7)\n",
    "sns.histplot(data=df, x= df[df.age_bin == pd.Interval(120, 200)].logerror)\n",
    "plt.title(\"120 and Up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d3db00",
   "metadata": {},
   "source": [
    "Looking at logerror by age_bin, they are generally normally distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b47d13",
   "metadata": {},
   "source": [
    "Maybe run an ANOVA test to see about the variances? \n",
    "\n",
    "First, Levene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa39525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#H0: Variances are equal\n",
    "#Ha: Variances are not equal\n",
    "\n",
    "stats.levene(\n",
    "    df[df.age_bin == pd.Interval(0, 20)].logerror,\n",
    "    df[df.age_bin == pd.Interval(20,40)].logerror,\n",
    "    df[df.age_bin == pd.Interval(40,60)].logerror,\n",
    "    df[df.age_bin == pd.Interval(60,80)].logerror,\n",
    "    df[df.age_bin == pd.Interval(80,100)].logerror,\n",
    "    df[df.age_bin == pd.Interval(100,120)].logerror,\n",
    "    df[df.age_bin == pd.Interval(120,200)].logerror\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ffe1c5",
   "metadata": {},
   "source": [
    "The results show that the null hypothesis is rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4236f3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.age_bin == pd.Interval(0, 20)].logerror.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa061669",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.age_bin == pd.Interval(120,200)].logerror.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1849b10",
   "metadata": {},
   "source": [
    "#### Anova testing of the logerror by age_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf98542",
   "metadata": {},
   "source": [
    "Set Hypothesis\n",
    "- 𝐻0 : Population means of logerror (by age_bin) are equal\n",
    "- 𝐻𝑎 : Population means of logerror (by age_bin) are not all equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07ebb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell runs an ANOVA test on the different 'age_bins'\n",
    "# We are demonstrating statistically that the age correlates to the logerror\n",
    "f, p = stats.f_oneway(\n",
    "    df[df.age_bin == pd.Interval(0, 20)].logerror,\n",
    "    df[df.age_bin == pd.Interval(20,40)].logerror,\n",
    "    df[df.age_bin == pd.Interval(40,60)].logerror,\n",
    "    df[df.age_bin == pd.Interval(60,80)].logerror,\n",
    "    df[df.age_bin == pd.Interval(80,100)].logerror,\n",
    "    df[df.age_bin == pd.Interval(100,120)].logerror,\n",
    "    df[df.age_bin == pd.Interval(120,200)].logerror\n",
    ")\n",
    "f, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0b8480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting our alpha and returning a statemtent on the validity of the ANOVA test by comparing alpha to the resulting p-value\n",
    "\n",
    "alpha = 0.05\n",
    "if p < alpha:\n",
    "    print(\"We reject H_O\")\n",
    "else:\n",
    "    print(\"We fail to reject $H_{0}$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19cb9c8",
   "metadata": {},
   "source": [
    "#### The anova test shows I can proceed with the understanding that the average logerror is different depending on the age of the home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3c0b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=df, y='logerror', x='age', col='county')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9fa1ab",
   "metadata": {},
   "source": [
    "This relplot shows age and logerror by count; any dignificant differences between the counties aren't clear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e53208",
   "metadata": {},
   "source": [
    "### What about a relationship between tax_value and logerror? (also: are these related targets?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f67c66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=df.tax_value, y=df.logerror, data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ec626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=df.tax_value, y=df.logerror, data=df, hue='county', alpha=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7305388f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=df.tax_value, y=df.logerror, data=df, col='county', alpha=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6488d71f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df.county=='Los_Angeles'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90246b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.county=='Orange'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e117118",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.county=='Ventura'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4675d7",
   "metadata": {},
   "source": [
    "### No clear impressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5db235",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='tax_value', y='logerror', data=df, scatter_kws={'alpha':.2},hue='county')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41db55ad",
   "metadata": {},
   "source": [
    "### Look like perfectly flat trend lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9ae7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
